{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "num_features = data.dtypes[data.dtypes != \"object\"].index\n",
    "for x in num_features:\n",
    "    if skew(data[x].dropna()) > 0.75:\n",
    "        data[x] = np.log1p(data[x])\n",
    "data = pd.get_dummies(data)\n",
    "data = data.fillna(data.mean())\n",
    "X_train = data[:train.shape[0]]\n",
    "X_test = data[train.shape[0]:]\n",
    "y = train.SalePrice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "def cv_rmse(model, X_train):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X_train, y, scoring = \"neg_mean_squared_error\", cv = kf))\n",
    "    return rmse;\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression - ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridges_alphas = [0.1, 0.5, 1, 3, 5, 7, 9, 10, 12, 14, 16, 18, 20, 22, 25,\n",
    "                30]\n",
    "ridge = RidgeCV(alphas = ridges_alphas, cv = kf)\n",
    "model_ridge = ridge.fit(X_train, y)\n",
    "lassocv_alpha = ridge.alpha_\n",
    "lassocv_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12749688124644226"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse(model_ridge, X_train).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.257944703741936, tolerance: 0.020670635975439527\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4674568950474134, tolerance: 0.020158113854077044\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0313822613713981, tolerance: 0.02136489634462787\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_alphas = [0.0001, 0.0002, 0.0004, 0.0006, 0.0008, 0.001, 0.002, \n",
    "               0.004, 0.006, 0.008, 0.01, 0.03, 0.07, 0.1, 0.3, 0.5, 0.7]\n",
    "lasso = LassoCV(alphas = lasso_alphas, cv = kf)\n",
    "model_lasso = lasso.fit(X_train, y)\n",
    "lassocv_alpha = lasso.alpha_\n",
    "lassocv_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.026667652510553808, tolerance: 0.018755727051471067\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06684196448771118, tolerance: 0.01830479696031895\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.25536110573749404, tolerance: 0.018657073785185097\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3169741097519605, tolerance: 0.018957619187673597\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3784218754423385, tolerance: 0.018257378411169835\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18906442832637538, tolerance: 0.0184956761998897\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.056192386435458985, tolerance: 0.01915927135809817\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.531013232666897, tolerance: 0.01967973662878661\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8277711385965691, tolerance: 0.01930136161304648\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5934062143844745, tolerance: 0.019503692364369142\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8180436390555013, tolerance: 0.018184589461124525\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15935081421640263, tolerance: 0.018489219573250337\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2929561122004962, tolerance: 0.018528315231219887\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5431864538226128, tolerance: 0.017865580166946483\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13452789003670418, tolerance: 0.018206557558674483\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9174665461715055, tolerance: 0.01866818446168442\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06289817782127471, tolerance: 0.018378049250312768\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6298546433965821, tolerance: 0.01893883742048688\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07098766900919529, tolerance: 0.01983066912505534\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1495394551401823, tolerance: 0.019392581094562024\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12087859481852092, tolerance: 0.01847839597586619\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12235646631445088"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse(model_lasso, X_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea               0.420654\n",
       "Neighborhood_StoneBr    0.118314\n",
       "Neighborhood_Crawfor    0.108035\n",
       "Neighborhood_NoRidge    0.088526\n",
       "Functional_Typ          0.074537\n",
       "Neighborhood_NridgHt    0.073322\n",
       "LotArea                 0.072525\n",
       "KitchenQual_Ex          0.069277\n",
       "Exterior1st_BrkFace     0.068871\n",
       "RoofMatl_WdShngl        0.062292\n",
       "BsmtQual_Ex             0.051444\n",
       "OverallQual             0.051296\n",
       "Condition1_Norm         0.045385\n",
       "OverallCond             0.042387\n",
       "Neighborhood_BrkSide    0.040869\n",
       "Neighborhood_Somerst    0.040237\n",
       "BsmtExposure_Gd         0.038670\n",
       "GarageCars              0.036823\n",
       "1stFlrSF                0.031050\n",
       "LotConfig_CulDSac       0.028828\n",
       "dtype: float64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "selected_features = coefficients.sort_values(ascending = False).head(20)\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13858015819132832"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb\n",
    "model_xgb = xgb.XGBRegressor().fit(X_train, y)\n",
    "\n",
    "cv_rmse(model_xgb, X_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: if the following code crashes, remove the \"n_job=-1\" parameter. This is sklearn's parallization bug. If the parameter is removed, the execution time will be very long since it will only use a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:58<00:00, 32.93s/trial, best loss: 0.015351419072119624]\n",
      "{'colsample_bylevel': 0.5089307368584586, 'colsample_bytree': 0.6660313658284291, 'learning_rate': 0.037, 'max_depth': 7.0, 'n_estimators': 3500.0, 'reg_lambda': 8.0, 'subsample': 0.6716479399150603}\n"
     ]
    }
   ],
   "source": [
    "#xgb+tuning \n",
    "xgboost_hyerparameters = {\n",
    "    'learning_rate': hp.quniform('learning_rate', 0, 0.3, 0.001),\n",
    "    'max_depth':hp.quniform('max_depth', 3,10,1),\n",
    "    'n_estimators':hp.quniform('n_estimators', 1000, 5000, 100),\n",
    "    #'gamma':hp.uniform('gamma', 0, 0.4),\n",
    "    'reg_lambda': hp.quniform('reg_lambda', 0, 25, 1),\n",
    "    'subsample':hp.uniform('subsample', 0.60, 0.95),\n",
    "    'colsample_bytree':hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'colsample_bylevel':hp.uniform('colsample_bylevel', 0.5, 1),     \n",
    "}\n",
    "\n",
    "def hyperparameter_tuning(hyerparameters):\n",
    "    hyerparameters = {\n",
    "        'learning_rate': hyerparameters['learning_rate'],\n",
    "        'max_depth': int(hyerparameters['max_depth']),\n",
    "        'n_estimators': int(hyerparameters['n_estimators']),\n",
    "        #'gamma': hyerparameters['gamma'],\n",
    "        'reg_lambda': hyerparameters['reg_lambda'],\n",
    "        'subsample': hyerparameters['subsample'],\n",
    "        'colsample_bytree': hyerparameters['colsample_bytree'],\n",
    "        'colsample_bylevel': hyerparameters['colsample_bylevel']     \n",
    "    }\n",
    "\n",
    "    model_xgboost = xgb.XGBRegressor(**hyerparameters)\n",
    "    return -cross_val_score(model_xgboost, X_train, y, scoring = 'neg_mean_squared_error', cv = 5, n_jobs = -1).mean()\n",
    "\n",
    "    \n",
    "        \n",
    "xgboost_final_hyerparameters = fmin(\n",
    "    fn = hyperparameter_tuning, \n",
    "    space = xgboost_hyerparameters, \n",
    "    max_evals = 20, \n",
    "    rstate = np.random.RandomState(1), \n",
    "    algo = tpe.suggest)\n",
    "\n",
    "print(xgboost_final_hyerparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12574854029667773"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(random_state=0,\n",
    "                        n_estimators=int(xgboost_final_hyerparameters['n_estimators']), \n",
    "                        colsample_bytree= xgboost_final_hyerparameters['colsample_bytree'],\n",
    "                        #gamma= xgboost_final_hyerparameters['gamma'],\n",
    "                        learning_rate= xgboost_final_hyerparameters['learning_rate'],\n",
    "                        max_depth= int(xgboost_final_hyerparameters['max_depth']),\n",
    "                        subsample= xgboost_final_hyerparameters['subsample'],\n",
    "                        colsample_bylevel= xgboost_final_hyerparameters['colsample_bylevel'],\n",
    "                        reg_lambda= xgboost_final_hyerparameters['reg_lambda']\n",
    "                       ).fit(X_train, y)\n",
    "\n",
    "cv_rmse(model_xgb, X_train).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boost-GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12584558500268123"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original gbr\n",
    "model_gbr = GradientBoostingRegressor().fit(X_train, y)\n",
    "cv_rmse(model_gbr, X_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: if the following code crashes, remove the \"n_job=-1\" parameter. This is sklearn's parallization bug. If the parameter is removed, the execution time will be very long since it will only use a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [17:31<00:00, 52.57s/trial, best loss: 1.412144088192948e-06] \n",
      "{'learning_rate': 0.0193, 'max_depth': 4.0, 'n_estimators': 4300.0}\n"
     ]
    }
   ],
   "source": [
    "#gbr+tuning\n",
    "gbr_hyerparameters = {\n",
    "    'learning_rate': hp.quniform('learning_rate', 0, 0.3, 0.0001),\n",
    "    'n_estimators': hp.quniform('n_estimators', 1000, 5000, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 3,10,1),\n",
    "    #'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1)\n",
    "}\n",
    "def hyperparameter_tuning(hyerparameters):\n",
    "    hyerparameters = {\n",
    "        'learning_rate': hyerparameters['learning_rate'],\n",
    "        'max_depth': int(hyerparameters['max_depth']),\n",
    "        'n_estimators': int(hyerparameters['n_estimators']),\n",
    "             \n",
    "    }\n",
    "    model_gbr = GradientBoostingRegressor(**hyerparameters)\n",
    "    return -cross_val_score(model_gbr, X_train, y, scoring ='neg_mean_squared_error', cv = 5, n_jobs=-1).mean()\n",
    "    \n",
    "        \n",
    "gbr_final_hyerparameters = fmin(\n",
    "    fn= hyperparameter_tuning, \n",
    "    space = gbr_hyerparameters,\n",
    "    max_evals = 20, \n",
    "    rstate = np.random.RandomState(1), \n",
    "    algo = tpe.suggest\n",
    ")\n",
    "\n",
    "print(gbr_final_hyerparameters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12027023494988247"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbr = GradientBoostingRegressor(\n",
    "    n_estimators = int(gbr_final_hyerparameters['n_estimators']), \n",
    "    learning_rate = gbr_final_hyerparameters['learning_rate'], \n",
    "    max_depth = gbr_final_hyerparameters['max_depth'], \n",
    "    max_features = 'sqrt', \n",
    "    #min_samples_leaf = int(gbr_final_hyerparameters['min_samples_leaf']), \n",
    "    min_samples_leaf = 15,\n",
    "    min_samples_split = 10, \n",
    "    loss='ls', \n",
    "    random_state = 42).fit(X_train, y)\n",
    "cv_rmse(model_gbr, X_train).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final output\n",
    "gbr_preds = np.expm1(model_gbr.predict(X_test))\n",
    "lasso_preds = np.expm1(model_lasso.predict(X_test))\n",
    "xgb_preds = np.expm1(model_xgb.predict(X_test))\n",
    "\n",
    "preds = 0.4 * lasso_preds + 0.6 * gbr_preds\n",
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\n",
    "solution.to_csv(\"final.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/Users/lilythegirl/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: delayed in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (0.11.0b1)\n",
      "Requirement already satisfied: hiredis in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from delayed) (2.0.0)\n",
      "Requirement already satisfied: redis in /Users/lilythegirl/opt/anaconda3/lib/python3.8/site-packages (from delayed) (3.5.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/Users/lilythegirl/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "!pip install delayed\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
